"""
ç¬¬å››è¯¾ï¼šé“¾ (Chains) - LCEL å®Œå…¨æŒ‡å—
å­¦ä¹ ç›®æ ‡ï¼š
1. ç†è§£ LCEL (LangChain Expression Language)
2. æŒæ¡æ ¸å¿ƒ Runnable ç»„ä»¶
3. å­¦ä¼šå„ç§è°ƒç”¨æ–¹å¼å’Œæ•°æ®æµè½¬
4. å®ç°é”™è¯¯å¤„ç†å’Œè°ƒè¯•
"""
import asyncio
from operator import itemgetter
from dotenv import load_dotenv
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import (
    RunnablePassthrough,
    RunnableParallel,
    RunnableLambda,
    RunnableBranch,
    chain,
)
from llm_factory import get_llm

load_dotenv()

llm = get_llm()


# ============================================================
# ç¬¬ä¸€éƒ¨åˆ†ï¼šLCEL åŸºç¡€
# ============================================================

def demo_simple_chain():
    """1.1 ç®€å•é“¾ - ç®¡é“æ“ä½œç¬¦"""
    print("=" * 60)
    print("1.1 ç®€å•é“¾ - ä½¿ç”¨ | ç®¡é“ç¬¦ç»„åˆç»„ä»¶")
    print("=" * 60)
    
    prompt = ChatPromptTemplate.from_template("ç”¨ä¸€å¥è¯è§£é‡Šä»€ä¹ˆæ˜¯{concept}")
    chain = prompt | llm | StrOutputParser()
    
    result = chain.invoke({"concept": "æœºå™¨å­¦ä¹ "})
    print(f"ç»“æœ: {result}")
    print(f"\né“¾çš„è¾“å…¥ Schema: {chain.input_schema.model_json_schema()}")
    print()


def demo_chain_equivalents():
    """1.2 ä¸‰ç§ç­‰ä»·çš„é“¾æ„å»ºæ–¹å¼"""
    print("=" * 60)
    print("1.2 ä¸‰ç§ç­‰ä»·çš„é“¾æ„å»ºæ–¹å¼")
    print("=" * 60)
    
    from langchain_core.runnables import RunnableSequence
    
    prompt = ChatPromptTemplate.from_template("ç”¨ä¸€å¥è¯è§£é‡Š{topic}")
    parser = StrOutputParser()
    
    # æ–¹å¼1: ç®¡é“æ“ä½œç¬¦ï¼ˆæ¨èï¼‰
    chain1 = prompt | llm | parser
    # æ–¹å¼2: pipe() æ–¹æ³•
    chain2 = prompt.pipe(llm).pipe(parser)
    # æ–¹å¼3: RunnableSequenceï¼ˆæ˜¾å¼ï¼‰
    chain3 = RunnableSequence(first=prompt, middle=[llm], last=parser)
    
    result = chain1.invoke({"topic": "Python"})
    print(f"ç»“æœ: {result}")
    print("ğŸ’¡ æ¨èä½¿ç”¨ç®¡é“æ“ä½œç¬¦ |ï¼Œæœ€ç®€æ´æ˜“è¯»")
    print()


# ============================================================
# ç¬¬äºŒéƒ¨åˆ†ï¼šæ ¸å¿ƒ Runnable ç»„ä»¶
# ============================================================

def demo_runnable_lambda():
    """2.1 RunnableLambda - åŒ…è£…è‡ªå®šä¹‰å‡½æ•°"""
    print("=" * 60)
    print("2.1 RunnableLambda - åŒ…è£…è‡ªå®šä¹‰å‡½æ•°")
    print("=" * 60)
    
    def add_emoji(text: str) -> str:
        return f"ğŸ‰ {text} ğŸ‰"
    
    def word_count(text: str) -> dict:
        return {"text": text, "word_count": len(text)}
    
    prompt = ChatPromptTemplate.from_template("ç”¨ä¸€å¥è¯ä»‹ç»{topic}")
    
    # åœ¨é“¾ä¸­ä½¿ç”¨è‡ªå®šä¹‰å‡½æ•°
    chain = prompt | llm | StrOutputParser() | RunnableLambda(add_emoji)
    result = chain.invoke({"topic": "LangChain"})
    print(f"å¸¦ emoji: {result}")
    
    # é“¾å¼å¤„ç†
    chain2 = prompt | llm | StrOutputParser() | RunnableLambda(word_count)
    result2 = chain2.invoke({"topic": "Python"})
    print(f"å¸¦å­—æ•°ç»Ÿè®¡: {result2}")
    print()


def demo_chain_decorator():
    """2.2 @chain è£…é¥°å™¨ - æ›´ä¼˜é›…çš„è‡ªå®šä¹‰é“¾"""
    print("=" * 60)
    print("2.2 @chain è£…é¥°å™¨ - æ›´ä¼˜é›…çš„è‡ªå®šä¹‰é“¾")
    print("=" * 60)
    
    @chain
    def analyze_topic(input_dict: dict) -> str:
        """è‡ªå®šä¹‰é“¾ï¼šåˆ†æä¸»é¢˜å¹¶è¿”å›æ ¼å¼åŒ–ç»“æœ"""
        topic = input_dict["topic"]
        
        prompt1 = ChatPromptTemplate.from_template("ç”¨ä¸€å¥è¯è§£é‡Š{topic}")
        explanation = (prompt1 | llm | StrOutputParser()).invoke({"topic": topic})
        
        prompt2 = ChatPromptTemplate.from_template("åˆ—ä¸¾{topic}çš„3ä¸ªåº”ç”¨åœºæ™¯ï¼Œæ¯ä¸ªç”¨ä¸€å¥è¯")
        applications = (prompt2 | llm | StrOutputParser()).invoke({"topic": topic})
        
        return f"ğŸ“š {topic}\n\nå®šä¹‰ï¼š{explanation}\n\nåº”ç”¨ï¼š\n{applications}"
    
    result = analyze_topic.invoke({"topic": "æ·±åº¦å­¦ä¹ "})
    print(result)
    print()


def demo_runnable_passthrough():
    """2.3 RunnablePassthrough - æ•°æ®é€ä¼ ä¸å¢å¼º"""
    print("=" * 60)
    print("2.3 RunnablePassthrough - æ•°æ®é€ä¼ ä¸å¢å¼º")
    print("=" * 60)
    
    # åŸºç¡€é€ä¼ 
    print("--- åŸºç¡€é€ä¼  ---")
    passthrough = RunnablePassthrough()
    print(f"é€ä¼ ç»“æœ: {passthrough.invoke({'name': 'Alice'})}")
    
    # assign() - æ·»åŠ æ–°å­—æ®µ
    print("\n--- assign() æ·»åŠ æ–°å­—æ®µ ---")
    enhanced = RunnablePassthrough.assign(
        text_length=lambda x: len(x.get("text", "")),
        uppercase=lambda x: x.get("text", "").upper()
    )
    result = enhanced.invoke({"text": "hello world", "id": 1})
    print(f"å¢å¼ºå: {result}")
    
    # å®é™…åº”ç”¨ï¼šRAG åœºæ™¯
    print("\n--- å®é™…åº”ç”¨ï¼šæ¨¡æ‹Ÿ RAG ---")
    def fake_retriever(query):
        return f"[æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£ï¼šå…³äº {query} çš„ä¿¡æ¯...]"
    
    prompt = ChatPromptTemplate.from_template(
        "æ ¹æ®ä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ï¼š\nä¸Šä¸‹æ–‡ï¼š{context}\né—®é¢˜ï¼š{question}"
    )
    
    rag_chain = (
        {"context": lambda x: fake_retriever(x["question"]), "question": itemgetter("question")}
        | prompt | llm | StrOutputParser()
    )
    result = rag_chain.invoke({"question": "ä»€ä¹ˆæ˜¯å‘é‡æ•°æ®åº“ï¼Ÿ"})
    print(f"RAG ç»“æœ: {result}")
    print()


def demo_runnable_parallel():
    """2.4 RunnableParallel - å¹¶è¡Œæ‰§è¡Œ"""
    print("=" * 60)
    print("2.4 RunnableParallel - å¹¶è¡Œæ‰§è¡Œå¤šä¸ªä»»åŠ¡")
    print("=" * 60)
    
    joke_prompt = ChatPromptTemplate.from_template("è®²ä¸€ä¸ªå…³äº{topic}çš„ç¬‘è¯ï¼Œä¸€å¥è¯")
    poem_prompt = ChatPromptTemplate.from_template("å†™ä¸€å¥å…³äº{topic}çš„è¯—")
    fact_prompt = ChatPromptTemplate.from_template("è¯´ä¸€ä¸ªå…³äº{topic}çš„æœ‰è¶£äº‹å®ï¼Œä¸€å¥è¯")
    
    parallel = RunnableParallel(
        joke=joke_prompt | llm | StrOutputParser(),
        poem=poem_prompt | llm | StrOutputParser(),
        fact=fact_prompt | llm | StrOutputParser()
    )
    
    results = parallel.invoke({"topic": "ç¨‹åºå‘˜"})
    print(f"ç¬‘è¯: {results['joke']}")
    print(f"è¯—å¥: {results['poem']}")
    print(f"äº‹å®: {results['fact']}")
    print()


def demo_runnable_branch():
    """2.5 RunnableBranch - æ¡ä»¶è·¯ç”±"""
    print("=" * 60)
    print("2.5 RunnableBranch - æ¡ä»¶è·¯ç”±åˆ†æ”¯")
    print("=" * 60)
    
    tech_prompt = ChatPromptTemplate.from_template("ä½ æ˜¯æŠ€æœ¯ä¸“å®¶ã€‚ç”¨ä¸“ä¸šæœ¯è¯­å›ç­”ï¼š{question}")
    casual_prompt = ChatPromptTemplate.from_template("ä½ æ˜¯å‹å¥½çš„åŠ©æ‰‹ã€‚ç”¨è½»æ¾çš„è¯­æ°”å›ç­”ï¼š{question}")
    default_prompt = ChatPromptTemplate.from_template("è¯·å›ç­”ï¼š{question}")
    
    tech_chain = tech_prompt | llm | StrOutputParser()
    casual_chain = casual_prompt | llm | StrOutputParser()
    default_chain = default_prompt | llm | StrOutputParser()
    
    def is_tech_question(x):
        keywords = ["ä»£ç ", "ç¼–ç¨‹", "ç®—æ³•", "API", "æ•°æ®åº“", "Python", "Java"]
        return any(kw in x.get("question", "") for kw in keywords)
    
    def is_casual_question(x):
        keywords = ["ç¬‘è¯", "æ•…äº‹", "æœ‰è¶£", "å¥½ç©", "æ¨è"]
        return any(kw in x.get("question", "") for kw in keywords)
    
    branch = RunnableBranch(
        (is_tech_question, tech_chain),
        (is_casual_question, casual_chain),
        default_chain
    )
    
    questions = [
        {"question": "Pythonçš„è£…é¥°å™¨æ˜¯ä»€ä¹ˆï¼Ÿ"},
        {"question": "è®²ä¸ªæœ‰è¶£çš„ç¬‘è¯"},
        {"question": "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"},
    ]
    
    for q in questions:
        result = branch.invoke(q)
        print(f"é—®é¢˜: {q['question']}")
        print(f"å›ç­”: {result}\n")


# ============================================================
# ç¬¬ä¸‰éƒ¨åˆ†ï¼šé¡ºåºé“¾ä¸æ•°æ®æµ
# ============================================================

def demo_sequential_chain():
    """3.1 é¡ºåºé“¾ - å¤šæ­¥éª¤ä¸²è”"""
    print("=" * 60)
    print("3.1 é¡ºåºé“¾ - å¤šæ­¥éª¤ä¸²è”æ‰§è¡Œ")
    print("=" * 60)
    
    translate_prompt = ChatPromptTemplate.from_template(
        "å°†ä»¥ä¸‹ä¸­æ–‡ç¿»è¯‘æˆè‹±æ–‡ï¼Œåªè¾“å‡ºç¿»è¯‘ç»“æœï¼š{text}"
    )
    translate_chain = translate_prompt | llm | StrOutputParser()
    
    summary_prompt = ChatPromptTemplate.from_template("Summarize in one sentence: {translated}")
    summary_chain = summary_prompt | llm | StrOutputParser()
    
    full_chain = (
        {"translated": translate_chain, "original": itemgetter("text")}
        | RunnablePassthrough.assign(summary=summary_chain)
    )
    
    result = full_chain.invoke({
        "text": "äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜æˆ‘ä»¬çš„ç”Ÿæ´»æ–¹å¼ï¼Œä»æ™ºèƒ½æ‰‹æœºåˆ°è‡ªåŠ¨é©¾é©¶æ±½è½¦ï¼ŒAIæ— å¤„ä¸åœ¨ã€‚"
    })
    print(f"åŸæ–‡: {result['original']}")
    print(f"ç¿»è¯‘: {result['translated']}")
    print(f"æ€»ç»“: {result['summary']}")
    print()


def demo_itemgetter():
    """3.2 itemgetter - æå–å­—å…¸å­—æ®µ"""
    print("=" * 60)
    print("3.2 itemgetter - æå–å’Œé‡ç»„æ•°æ®")
    print("=" * 60)
    
    prompt = ChatPromptTemplate.from_template("ç”¨æˆ· {name} é—®ï¼š{question}\nè¯·å‹å¥½åœ°å›ç­”ã€‚")
    
    chain = (
        {"name": itemgetter("user_info") | RunnableLambda(lambda x: x["name"]), "question": itemgetter("query")}
        | prompt | llm | StrOutputParser()
    )
    
    result = chain.invoke({"user_info": {"name": "å°æ˜", "age": 25}, "query": "Pythonæ€ä¹ˆå­¦ï¼Ÿ"})
    print(f"ç»“æœ: {result}")
    print()


# ============================================================
# ç¬¬å››éƒ¨åˆ†ï¼šè°ƒç”¨æ–¹å¼
# ============================================================

def demo_invoke_methods():
    """4.1 åŒæ­¥è°ƒç”¨æ–¹å¼"""
    print("=" * 60)
    print("4.1 åŒæ­¥è°ƒç”¨æ–¹å¼: invoke / stream / batch")
    print("=" * 60)
    
    prompt = ChatPromptTemplate.from_template("ç”¨ä¸€å¥è¯ä»‹ç»{topic}")
    chain = prompt | llm | StrOutputParser()
    
    print("--- invoke() å•ä¸ªè°ƒç”¨ ---")
    result = chain.invoke({"topic": "Python"})
    print(f"ç»“æœ: {result}")
    
    print("\n--- stream() æµå¼è¾“å‡º ---")
    print("ç»“æœ: ", end="")
    for chunk in chain.stream({"topic": "æœºå™¨å­¦ä¹ çš„åº”ç”¨åœºæ™¯"}):
        print(chunk, end="", flush=True)
    print()
    
    print("\n--- batch() æ‰¹é‡å¤„ç† ---")
    topics = [{"topic": "Java"}, {"topic": "Go"}, {"topic": "Rust"}]
    results = chain.batch(topics)
    for topic, result in zip(topics, results):
        print(f"{topic['topic']}: {result}")
    print()


async def demo_async_methods():
    """4.2 å¼‚æ­¥è°ƒç”¨æ–¹å¼"""
    print("=" * 60)
    print("4.2 å¼‚æ­¥è°ƒç”¨æ–¹å¼: ainvoke / astream / abatch")
    print("=" * 60)
    
    prompt = ChatPromptTemplate.from_template("ç”¨ä¸€å¥è¯ä»‹ç»{topic}")
    chain = prompt | llm | StrOutputParser()
    
    print("--- ainvoke() å¼‚æ­¥è°ƒç”¨ ---")
    result = await chain.ainvoke({"topic": "Docker"})
    print(f"ç»“æœ: {result}")
    
    print("\n--- astream() å¼‚æ­¥æµå¼ ---")
    print("ç»“æœ: ", end="")
    async for chunk in chain.astream({"topic": "Kubernetes"}):
        print(chunk, end="", flush=True)
    print()
    
    print("\n--- abatch() å¼‚æ­¥æ‰¹é‡ ---")
    topics = [{"topic": "Redis"}, {"topic": "MongoDB"}]
    results = await chain.abatch(topics)
    for topic, result in zip(topics, results):
        print(f"{topic['topic']}: {result}")
    
    print("\n--- asyncio.gather() å¹¶å‘è°ƒç”¨ ---")
    tasks = [chain.ainvoke({"topic": "MySQL"}), chain.ainvoke({"topic": "PostgreSQL"})]
    results = await asyncio.gather(*tasks)
    for result in results:
        print(f"ç»“æœ: {result}")
    print()


# ============================================================
# ç¬¬äº”éƒ¨åˆ†ï¼šé”™è¯¯å¤„ç†
# ============================================================

def demo_retry():
    """5.1 with_retry - è‡ªåŠ¨é‡è¯•"""
    print("=" * 60)
    print("5.1 with_retry - è‡ªåŠ¨é‡è¯•æœºåˆ¶")
    print("=" * 60)
    
    prompt = ChatPromptTemplate.from_template("ç”¨ä¸€å¥è¯ä»‹ç»{topic}")
    chain = prompt | llm | StrOutputParser()
    
    chain_with_retry = chain.with_retry(stop_after_attempt=3, wait_exponential_jitter=True)
    result = chain_with_retry.invoke({"topic": "é”™è¯¯å¤„ç†"})
    print(f"ç»“æœ: {result}")
    print("ğŸ’¡ with_retry é€‚åˆå¤„ç†ç½‘ç»œæ³¢åŠ¨ã€API é™æµç­‰ä¸´æ—¶é”™è¯¯")
    print()


def demo_fallback():
    """5.2 with_fallbacks - é™çº§å¤‡é€‰"""
    print("=" * 60)
    print("5.2 with_fallbacks - é™çº§å¤‡é€‰æ–¹æ¡ˆ")
    print("=" * 60)
    
    main_prompt = ChatPromptTemplate.from_template("è¯¦ç»†è§£é‡Š{topic}çš„åŸç†")
    main_chain = main_prompt | llm | StrOutputParser()
    
    fallback_prompt = ChatPromptTemplate.from_template("ç®€å•ä»‹ç»{topic}")
    fallback_chain = fallback_prompt | llm | StrOutputParser()
    
    chain_with_fallback = main_chain.with_fallbacks([fallback_chain])
    result = chain_with_fallback.invoke({"topic": "é‡å­è®¡ç®—"})
    print(f"ç»“æœ: {result}")
    print("ğŸ’¡ with_fallbacks é€‚åˆä¸»æ¨¡å‹ä¸å¯ç”¨æ—¶åˆ‡æ¢åˆ°å¤‡ç”¨æ¨¡å‹")
    print()


# ============================================================
# ç¬¬å…­éƒ¨åˆ†ï¼šé…ç½®ä¸è°ƒè¯•
# ============================================================

def demo_bind():
    """6.1 bind - ç»‘å®šå‚æ•°"""
    print("=" * 60)
    print("6.1 bind - ç»‘å®šå›ºå®šå‚æ•°")
    print("=" * 60)
    
    llm_with_stop = llm.bind(stop=["\n"])
    prompt = ChatPromptTemplate.from_template("åˆ—ä¸¾3ä¸ª{topic}ï¼š\n1.")
    chain = prompt | llm_with_stop | StrOutputParser()
    
    result = chain.invoke({"topic": "ç¼–ç¨‹è¯­è¨€"})
    print(f"ç»“æœï¼ˆé‡åˆ°æ¢è¡Œåœæ­¢ï¼‰: 1.{result}")
    print()


def demo_config():
    """6.2 with_config - æ·»åŠ é…ç½®"""
    print("=" * 60)
    print("6.2 with_config - æ·»åŠ  tags å’Œ metadata")
    print("=" * 60)
    
    prompt = ChatPromptTemplate.from_template("ä»‹ç»{topic}")
    chain = prompt | llm | StrOutputParser()
    
    result = chain.invoke(
        {"topic": "LangSmith"},
        config={"run_name": "demo_config_run", "tags": ["runtime_tag"], "metadata": {"user_id": "test"}}
    )
    print(f"ç»“æœ: {result}")
    print("ğŸ’¡ tags å’Œ metadata åœ¨ LangSmith ä¸­å¯ç”¨äºè¿‡æ»¤å’Œåˆ†æ")
    print()


def demo_debug():
    """6.3 è°ƒè¯•æŠ€å·§"""
    print("=" * 60)
    print("6.3 è°ƒè¯•æŠ€å·§ - æŸ¥çœ‹é“¾çš„ç»“æ„")
    print("=" * 60)
    
    prompt = ChatPromptTemplate.from_template("ä»‹ç»{topic}")
    chain = prompt | llm | StrOutputParser()
    
    print("è¾“å…¥ Schema:")
    print(chain.input_schema.model_json_schema())
    print("\nè¾“å‡º Schema:")
    print(chain.output_schema.model_json_schema())
    print(f"\né“¾çš„ç¬¬ä¸€æ­¥: {chain.first}")
    print(f"é“¾çš„æœ€åä¸€æ­¥: {chain.last}")
    print()


# ============================================================
# ä¸»å‡½æ•°
# ============================================================

async def run_async_demos():
    await demo_async_methods()


def main():
    print("\nğŸ”— ç¬¬å››è¯¾ï¼šé“¾ (Chains) - LCEL å®Œå…¨æŒ‡å—\n")
    
    print("\n" + "=" * 60)
    print("ğŸ“š ç¬¬ä¸€éƒ¨åˆ†ï¼šLCEL åŸºç¡€")
    print("=" * 60)
    demo_simple_chain()
    demo_chain_equivalents()
    
    print("\n" + "=" * 60)
    print("ğŸ“š ç¬¬äºŒéƒ¨åˆ†ï¼šæ ¸å¿ƒ Runnable ç»„ä»¶")
    print("=" * 60)
    demo_runnable_lambda()
    demo_chain_decorator()
    demo_runnable_passthrough()
    demo_runnable_parallel()
    demo_runnable_branch()
    
    print("\n" + "=" * 60)
    print("ğŸ“š ç¬¬ä¸‰éƒ¨åˆ†ï¼šé¡ºåºé“¾ä¸æ•°æ®æµ")
    print("=" * 60)
    demo_sequential_chain()
    demo_itemgetter()
    
    print("\n" + "=" * 60)
    print("ğŸ“š ç¬¬å››éƒ¨åˆ†ï¼šè°ƒç”¨æ–¹å¼")
    print("=" * 60)
    demo_invoke_methods()
    asyncio.run(run_async_demos())
    
    print("\n" + "=" * 60)
    print("ğŸ“š ç¬¬äº”éƒ¨åˆ†ï¼šé”™è¯¯å¤„ç†")
    print("=" * 60)
    demo_retry()
    demo_fallback()
    
    print("\n" + "=" * 60)
    print("ğŸ“š ç¬¬å…­éƒ¨åˆ†ï¼šé…ç½®ä¸è°ƒè¯•")
    print("=" * 60)
    demo_bind()
    demo_config()
    demo_debug()
    
    print("\n" + "=" * 60)
    print("ğŸ“Œ ç¬¬å››è¯¾æ€»ç»“")
    print("=" * 60)
    print("""
    æ ¸å¿ƒç»„ä»¶                ç”¨é€”
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    RunnableLambda         åŒ…è£…è‡ªå®šä¹‰ Python å‡½æ•°
    RunnablePassthrough    é€ä¼ æ•°æ® / assign() å¢å¼º
    RunnableParallel       å¹¶è¡Œæ‰§è¡Œå¤šä¸ªé“¾
    RunnableBranch         æ¡ä»¶è·¯ç”±åˆ†æ”¯
    @chain è£…é¥°å™¨          ä¼˜é›…å®šä¹‰è‡ªå®šä¹‰é“¾
    
    è°ƒç”¨æ–¹å¼                é€‚ç”¨åœºæ™¯
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    invoke()               å•ä¸ªåŒæ­¥è°ƒç”¨
    stream()               æµå¼è¾“å‡ºï¼ˆç”¨æˆ·äº¤äº’ï¼‰
    batch()                æ‰¹é‡å¤„ç†
    ainvoke/astream/abatch å¼‚æ­¥ç‰ˆæœ¬ï¼ˆWebæœåŠ¡ï¼‰
    
    é”™è¯¯å¤„ç†                ç”¨é€”
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with_retry()           è‡ªåŠ¨é‡è¯•ï¼ˆç½‘ç»œæ³¢åŠ¨ï¼‰
    with_fallbacks()       é™çº§å¤‡é€‰ï¼ˆæ¨¡å‹åˆ‡æ¢ï¼‰
    
    é…ç½®è°ƒè¯•                ç”¨é€”
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    bind()                 ç»‘å®šå›ºå®šå‚æ•°
    with_config()          æ·»åŠ  tags/metadata
    input_schema           æŸ¥çœ‹è¾“å…¥ç±»å‹
    """)


if __name__ == "__main__":
    main()
